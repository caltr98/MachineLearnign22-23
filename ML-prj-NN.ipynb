{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1Q3_gKI7tUv156l36uDSyp3fo4lGMn8IP","timestamp":1706043561620},{"file_id":"1Wf59G1uT25UwbNDfU-1t1cypslHHei3h","timestamp":1704451427420}],"gpuType":"V100"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.ensemble import AdaBoostRegressor\n","from sklearn.model_selection import GridSearchCV, KFold\n","from sklearn.multioutput import MultiOutputRegressor\n","from sklearn.model_selection import train_test_split\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, LSTM, Dropout\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, LeakyReLU\n","from tensorflow.keras.optimizers import SGD\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.callbacks import LearningRateScheduler\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout\n","from sklearn.model_selection import RandomizedSearchCV\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.optimizers import Adam\n","\n","from tensorflow.keras.callbacks import EarlyStopping,ReduceLROnPlateau\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.pipeline import Pipeline\n","from sklearn.metrics import mean_squared_error\n","\n","import numpy as np\n","from numpy import linalg\n","import math\n"],"metadata":{"id":"Pbc4-CQPaCRe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","\n","if tf.test.gpu_device_name():\n","    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n","else:\n","    print(\"Please install GPU version of TF\")\n"],"metadata":{"id":"kVNoudZVFnKh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706740606840,"user_tz":-60,"elapsed":7,"user":{"displayName":"Giovanni Cupitó","userId":"11305903449971326153"}},"outputId":"d84dee5c-0e0a-4307-abeb-fe013a715a0d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Default GPU Device: /device:GPU:0\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"R5tTNVbIc2HG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#load dataset\n","# do not use zero\n","df= pd.read_csv('./ML-CUP23-TR.csv', sep=\",\", low_memory=False, header = None,  usecols=[1,2,3,4,5,6,7,8,9,10,11,12,13], names=[1,2,3,4,5,6,7,8,9,10,'x','y','z'], skiprows=range(0, 7))\n","y_labels=df[['x','y','z']]\n","features_df = df[[1,2,3,4,5,6,7,8,9,10]]\n","display(df)"],"metadata":{"id":"G9IGCeHrcjiL","colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"status":"ok","timestamp":1706740606841,"user_tz":-60,"elapsed":5,"user":{"displayName":"Giovanni Cupitó","userId":"11305903449971326153"}},"outputId":"e31ac34b-aad4-4a01-e8b5-fc68cbc1d8d9"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["        1         2         3         4         5         6         7  \\\n","0       1 -0.917280 -0.712727 -0.989904  0.992819  0.993649  0.995543   \n","1       2 -0.858784  0.998755 -0.998396  0.999909  0.316503 -0.951897   \n","2       3 -0.990441  0.958726 -0.998675  0.997216  0.987166  0.356483   \n","3       4  0.937117  0.984474 -0.612420  0.999812  0.728623 -0.539962   \n","4       5 -0.906628 -0.884567 -0.932487  0.941037  0.978134  0.998179   \n","..    ...       ...       ...       ...       ...       ...       ...   \n","995   996 -0.803560 -0.878859 -0.978391  0.957539  0.996655  0.996924   \n","996   997  0.718841  0.995748 -0.942678  0.999929  0.747763 -0.808726   \n","997   998 -0.977912 -0.971108  0.956233 -0.979524  0.222033  0.986609   \n","998   999  0.284803 -0.988684 -0.427197  0.883317  0.993302  0.999500   \n","999  1000 -0.987580  0.993488 -0.998944  0.999703  0.936830 -0.564176   \n","\n","            8         9        10         x          y          z  \n","0    0.711074  0.407645 -0.688548  0.616890   7.897453 -35.936382  \n","1   -0.163139  0.980982  0.661759 -0.800155  -9.330632  19.901571  \n","2   -0.279689  0.599163 -0.684630  0.922901  14.849400   3.374090  \n","3   -0.165939  0.999352 -0.921444 -0.974766 -46.591854  13.734777  \n","4    0.749606 -0.590599 -0.508268  0.691798   8.217500 -45.885254  \n","..        ...       ...       ...       ...        ...        ...  \n","995 -0.226305  0.097814 -0.922666  0.934153  15.389553 -41.068806  \n","996  0.176132  0.999100 -0.753970 -0.969009 -36.228770  13.067430  \n","997  0.658273 -0.987310  0.937697  0.143420   7.265506 -53.497242  \n","998 -0.019456 -0.648110 -0.955231  0.901298   5.545274 -63.348396  \n","999  0.262568  0.892081 -0.198204  0.494586   6.160610   8.321016  \n","\n","[1000 rows x 13 columns]"],"text/html":["\n","  <div id=\"df-b26af150-968a-4492-81b4-170e1a213d3e\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>x</th>\n","      <th>y</th>\n","      <th>z</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>-0.917280</td>\n","      <td>-0.712727</td>\n","      <td>-0.989904</td>\n","      <td>0.992819</td>\n","      <td>0.993649</td>\n","      <td>0.995543</td>\n","      <td>0.711074</td>\n","      <td>0.407645</td>\n","      <td>-0.688548</td>\n","      <td>0.616890</td>\n","      <td>7.897453</td>\n","      <td>-35.936382</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>-0.858784</td>\n","      <td>0.998755</td>\n","      <td>-0.998396</td>\n","      <td>0.999909</td>\n","      <td>0.316503</td>\n","      <td>-0.951897</td>\n","      <td>-0.163139</td>\n","      <td>0.980982</td>\n","      <td>0.661759</td>\n","      <td>-0.800155</td>\n","      <td>-9.330632</td>\n","      <td>19.901571</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>-0.990441</td>\n","      <td>0.958726</td>\n","      <td>-0.998675</td>\n","      <td>0.997216</td>\n","      <td>0.987166</td>\n","      <td>0.356483</td>\n","      <td>-0.279689</td>\n","      <td>0.599163</td>\n","      <td>-0.684630</td>\n","      <td>0.922901</td>\n","      <td>14.849400</td>\n","      <td>3.374090</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>0.937117</td>\n","      <td>0.984474</td>\n","      <td>-0.612420</td>\n","      <td>0.999812</td>\n","      <td>0.728623</td>\n","      <td>-0.539962</td>\n","      <td>-0.165939</td>\n","      <td>0.999352</td>\n","      <td>-0.921444</td>\n","      <td>-0.974766</td>\n","      <td>-46.591854</td>\n","      <td>13.734777</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>-0.906628</td>\n","      <td>-0.884567</td>\n","      <td>-0.932487</td>\n","      <td>0.941037</td>\n","      <td>0.978134</td>\n","      <td>0.998179</td>\n","      <td>0.749606</td>\n","      <td>-0.590599</td>\n","      <td>-0.508268</td>\n","      <td>0.691798</td>\n","      <td>8.217500</td>\n","      <td>-45.885254</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>995</th>\n","      <td>996</td>\n","      <td>-0.803560</td>\n","      <td>-0.878859</td>\n","      <td>-0.978391</td>\n","      <td>0.957539</td>\n","      <td>0.996655</td>\n","      <td>0.996924</td>\n","      <td>-0.226305</td>\n","      <td>0.097814</td>\n","      <td>-0.922666</td>\n","      <td>0.934153</td>\n","      <td>15.389553</td>\n","      <td>-41.068806</td>\n","    </tr>\n","    <tr>\n","      <th>996</th>\n","      <td>997</td>\n","      <td>0.718841</td>\n","      <td>0.995748</td>\n","      <td>-0.942678</td>\n","      <td>0.999929</td>\n","      <td>0.747763</td>\n","      <td>-0.808726</td>\n","      <td>0.176132</td>\n","      <td>0.999100</td>\n","      <td>-0.753970</td>\n","      <td>-0.969009</td>\n","      <td>-36.228770</td>\n","      <td>13.067430</td>\n","    </tr>\n","    <tr>\n","      <th>997</th>\n","      <td>998</td>\n","      <td>-0.977912</td>\n","      <td>-0.971108</td>\n","      <td>0.956233</td>\n","      <td>-0.979524</td>\n","      <td>0.222033</td>\n","      <td>0.986609</td>\n","      <td>0.658273</td>\n","      <td>-0.987310</td>\n","      <td>0.937697</td>\n","      <td>0.143420</td>\n","      <td>7.265506</td>\n","      <td>-53.497242</td>\n","    </tr>\n","    <tr>\n","      <th>998</th>\n","      <td>999</td>\n","      <td>0.284803</td>\n","      <td>-0.988684</td>\n","      <td>-0.427197</td>\n","      <td>0.883317</td>\n","      <td>0.993302</td>\n","      <td>0.999500</td>\n","      <td>-0.019456</td>\n","      <td>-0.648110</td>\n","      <td>-0.955231</td>\n","      <td>0.901298</td>\n","      <td>5.545274</td>\n","      <td>-63.348396</td>\n","    </tr>\n","    <tr>\n","      <th>999</th>\n","      <td>1000</td>\n","      <td>-0.987580</td>\n","      <td>0.993488</td>\n","      <td>-0.998944</td>\n","      <td>0.999703</td>\n","      <td>0.936830</td>\n","      <td>-0.564176</td>\n","      <td>0.262568</td>\n","      <td>0.892081</td>\n","      <td>-0.198204</td>\n","      <td>0.494586</td>\n","      <td>6.160610</td>\n","      <td>8.321016</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1000 rows × 13 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b26af150-968a-4492-81b4-170e1a213d3e')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-b26af150-968a-4492-81b4-170e1a213d3e button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-b26af150-968a-4492-81b4-170e1a213d3e');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-caa6088d-a27a-4108-8daf-bc31c00b9757\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-caa6088d-a27a-4108-8daf-bc31c00b9757')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-caa6088d-a27a-4108-8daf-bc31c00b9757 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{}}]},{"cell_type":"code","source":["train_x, test_x, train_y, test_y = train_test_split(features_df, y_labels, stratify =None, test_size=0.40, random_state = 42, shuffle=False)"],"metadata":{"id":"iXtMD6wRnGse"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Functions Definition"],"metadata":{"id":"_56tPOUN8flu"}},{"cell_type":"code","source":["tf.keras.utils.set_random_seed(42)"],"metadata":{"id":"zxS2SXIY11tW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def perform_complete_grid_search(train_x, train_y, param_grid):\n","    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n","    all_models = []\n","\n","    combination_count = 0  # Counter for combinations\n","\n","    total_combinations = len(param_grid['units1']) * len(param_grid['activation']) * len(param_grid['l2_reg']) * len(param_grid['units2']) * len(param_grid['units3']) * len(param_grid['dropout_rate']) * len(param_grid['learning_rate'])\n","    print(f\"Total Combinations: {total_combinations}\")\n","\n","    for units1 in param_grid['units1']:\n","        for activation in param_grid['activation']:\n","            for l2_reg in param_grid['l2_reg']:\n","                for units2 in param_grid['units2']:\n","                    for units3 in param_grid['units3']:\n","                        for dropout_rate in param_grid['dropout_rate']:\n","                            for learning_rate in param_grid['learning_rate']:\n","                                fold_scores = []\n","                                for train_index, val_index in kf.split(train_x):\n","                                    X_train_fold, X_val_fold = train_x.iloc[train_index], train_x.iloc[val_index]\n","                                    y_train_fold, y_val_fold = train_y.iloc[train_index], train_y.iloc[val_index]\n","\n","                                    scaler = StandardScaler()\n","                                    X_train_fold_scaled = scaler.fit_transform(X_train_fold)\n","                                    X_val_fold_scaled = scaler.transform(X_val_fold)\n","                                    tf.keras.backend.clear_session() # releases the global state: this helps\n","                                                                      # avoid clutter from old models and layers\n","                                    tf.keras.utils.set_random_seed(42)\n","                                    model = create_model(units1=units1, activation1=activation, l2_reg1=l2_reg,\n","                                                         units2=units2, activation2=activation, l2_reg2=l2_reg,\n","                                                         units3=units3, activation3=activation, l2_reg3=l2_reg,\n","                                                         dropout_rate=dropout_rate, learning_rate=learning_rate)\n","                                    with tf.device(\"device:GPU:0\"):\n","                                      model.fit(X_train_fold_scaled, y_train_fold, epochs=100, batch_size=64, verbose=0)\n","\n","                                    val_pred = model.predict(X_val_fold_scaled)\n","                                    val_mse = mean_squared_error(y_val_fold, val_pred)\n","                                    fold_scores.append(val_mse)\n","\n","                                avg_mse = np.mean(fold_scores)\n","                                std_mse = np.std(fold_scores)\n","\n","                                all_models.append({\n","                                    'params': {\n","                                        'units1': units1, 'activation1': activation, 'l2_reg': l2_reg,\n","                                        'units2': units2, 'activation2': activation, 'l2_reg': l2_reg,\n","                                        'units3': units3, 'activation3': activation, 'l2_reg': l2_reg,\n","                                        'dropout_rate': dropout_rate, 'learning_rate': learning_rate\n","                                    },\n","                                    'avg_mse': avg_mse,\n","                                    'std_mse': std_mse\n","                                })\n","\n","                                combination_count += 1\n","                                print(f\"Combination {combination_count}:\")\n","                                print(f\"   Units1: {units1}, Activation1: {activation}, L2_reg: {l2_reg}\")\n","                                print(f\"   Units2: {units2}, Activation2: {activation}, L2_reg: {l2_reg}\")\n","                                print(f\"   Units3: {units3}, Activation3: {activation}, L2_reg: {l2_reg}\")\n","                                print(f\"   Dropout Rate: {dropout_rate}, Learning Rate: {learning_rate}\")\n","                                print(f\"   Average MSE: {avg_mse:.4f}, Std MSE: {std_mse:.4f}\")\n","\n","    # Sort all models by the average MSE\n","    all_models.sort(key=lambda x: x['avg_mse'])\n","\n","    return all_models\n"],"metadata":{"id":"u01jeRlFy7O2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_model_base(units1=32, activationf='tanh', initializer1='random_uniform', l2_reg=0.01,\n","                 units2=32, initializer2='random_uniform',\n","                 units3=32, initializer3='random_uniform',\n","                 dropout_rate=0.1, learning_rate=0.01, beta_1=0.9, beta_2=0.999):\n","    model = Sequential()\n","    model.add(Dense(units1, activation=activationf, kernel_initializer=initializer1,\n","                    kernel_regularizer=l2(l2_reg), input_shape=(10,)))  # Adjust the input_shape based on your data\n","    model.add(Dropout(dropout_rate))\n","    model.add(Dense(units2, activation=activationf, kernel_initializer=initializer2,\n","                    kernel_regularizer=l2(l2_reg)))\n","    model.add(Dropout(dropout_rate))\n","    model.add(Dense(units3, activation=activationf, kernel_initializer=initializer3,\n","                    kernel_regularizer=l2(l2_reg)))\n","    model.add(Dense(3, activation='linear'))  # Adjust the output layer based on your requirements\n","    model.compile(optimizer=Adam(learning_rate=learning_rate, beta_1=beta_1, beta_2=beta_2), loss='mean_squared_error')\n","    return model\n"],"metadata":{"id":"2dCnXPE2v97i"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Model create, default parameters are the one resulting from the hyperparameters tuning"],"metadata":{"id":"QGcROKQd8jz8"}},{"cell_type":"code","source":["def create_model(units1=32, activation1='tanh', initializer1='glorot_uniform', l2_reg1=0.1,\n","                 units2=32, activation2='tanh', initializer2='random_uniform', l2_reg2=3.1,\n","                 units3=32, activation3='relu', initializer3='random_normal', l2_reg3=0.1,\n","                 dropout_rate=0.1, learning_rate=0.01, beta_1=0.99, beta_2=0.999):\n","    model = Sequential()\n","    model.add(Dense(units1, activation=activation1, kernel_initializer=initializer1,\n","                    kernel_regularizer=l2(l2_reg1), input_shape=(10,)))  # Adjust the input_shape based on your data\n","    model.add(Dropout(dropout_rate))\n","    model.add(Dense(units2, activation=activation2, kernel_initializer=initializer2,\n","                    kernel_regularizer=l2(l2_reg2)))\n","    model.add(Dropout(dropout_rate))\n","    model.add(Dense(units3, activation=activation3, kernel_initializer=initializer3,\n","                    kernel_regularizer=l2(l2_reg3)))\n","    model.add(Dense(3, activation='linear'))  # Adjust the output layer based on your requirements\n","    model.compile(optimizer=Adam(learning_rate=learning_rate, beta_1=beta_1, beta_2=beta_2), loss='mean_squared_error')\n","    return model"],"metadata":{"id":"fG7l6UJW8jZc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["(Exhaustive)GridSearch cross validation definition"],"metadata":{"id":"FhJ7NaBntsdu"}},{"cell_type":"code","source":["def GridSearchCV_Call(param_grid):\n","  keras_model = KerasRegressor(model=create_model_base, epochs=100, batch_size=64, verbose=0)\n","\n","  # Create a Pipeline\n","  pipeline = Pipeline([\n","      ('scaler', StandardScaler()),\n","      ('model', keras_model)\n","  ])\n","\n","  #pipeline.set_params(model__c= param_dist)\n","  # Initialize RandomizedSearchCV\n","  grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid,\n","                                     cv=5, verbose=19,scoring='neg_mean_squared_error',n_jobs=-1)\n","\n","  # Perform the search (assuming train_x and train_y are already defined)\n","  grid_search.fit(train_x, train_y)\n","  return grid_search"],"metadata":{"id":"BzvANbc9trK8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["RandomGridSearch cross validation definition"],"metadata":{"id":"YnbhvJ6D8mDD"}},{"cell_type":"code","source":["def RandomizedSearchCV_Call(param_dist,n_iter=60):\n","  keras_model = KerasRegressor(model=create_model, epochs=100, batch_size=64, verbose=0)\n","\n","  # Create a Pipeline\n","  pipeline = Pipeline([\n","      ('scaler', StandardScaler()),\n","      ('model', keras_model)\n","  ])\n","\n","  #pipeline.set_params(model__c= param_dist)\n","  # Initialize RandomizedSearchCV\n","  random_search = RandomizedSearchCV(estimator=pipeline, param_distributions=param_dist,\n","                                    n_iter=n_iter , cv=5, verbose=19, random_state=42,scoring='neg_mean_squared_error')\n","\n","  # Perform the search (assuming train_x and train_y are already defined)\n","  random_search.fit(train_x, train_y)\n","  return random_search"],"metadata":{"id":"MOe9k-KA8qav"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Return Top 10 from RandomSearchCV"],"metadata":{"id":"kVzjNTyu9U4G"}},{"cell_type":"code","source":["def listing_top_10(search):\n","  # Retrieve the top 10 models\n","  top_10_indices = np.argsort(-search.cv_results_['mean_test_score'])[:10]\n","  top_10_scores = search.cv_results_['mean_test_score'][top_10_indices]\n","  top_10_std = search.cv_results_['std_test_score'][top_10_indices]\n","  top_10_params = [search.cv_results_['params'][i] for i in top_10_indices]\n","\n","  for score, std, params in zip(top_10_scores, top_10_std, top_10_params):\n","      print(f\"Score: {score}, Std. Dev: {std}, Parameters: {params}\")\n"],"metadata":{"id":"_Ew9k_DW9UEI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Plot of K Fold"],"metadata":{"id":"aC2n8TLob3EC"}},{"cell_type":"code","source":["def plot_aggregated_histories(all_histories):\n","    # Determine the minimum length of history among all folds\n","    min_length = min(len(hist.history['loss']) for hist in all_histories)\n","\n","    # Truncate all histories to the minimum length\n","    truncated_metric_values = [hist.history['loss'][:min_length] for hist in all_histories]\n","    truncated_val_metric_values = [hist.history['val_loss_fold' ][:min_length] for hist in all_histories]\n","\n","    # Calculate the mean and standard deviation for the truncated histories\n","    mean_metric_values = np.mean(truncated_metric_values, axis=0)\n","    mean_val_metric_values = np.mean(truncated_val_metric_values, axis=0)\n","    std_metric_values = np.std(truncated_metric_values, axis=0)\n","    std_val_metric_values = np.std(truncated_val_metric_values, axis=0)\n","\n","    # Plotting\n","    epochs = range(1, min_length + 1)\n","    plt.figure(figsize=(12, 6))\n","\n","    # Plot training metric\n","    plt.plot(epochs, mean_metric_values, label='Mean Training loss')\n","    plt.fill_between(epochs, mean_metric_values - std_metric_values, mean_metric_values + std_metric_values, alpha=0.3, color='blue')  # Fill between the lines with blue color\n","\n","    # Plot validation metric\n","    plt.plot(epochs, mean_val_metric_values, linestyle='dashdot', label='Mean Validation loss' )\n","    plt.fill_between(epochs, mean_val_metric_values - std_val_metric_values, mean_val_metric_values + std_val_metric_values, alpha=0.25, color='orange')  # Fill between the lines with orange color\n","\n","    plt.title('Mean Training and Validation Mean Squared Error (MSE) per Epoch in a 5-Fold Cross-Validation')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('MSE')\n","    plt.legend()\n","    plt.show()\n"],"metadata":{"id":"VtpRWgN0Ouc5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_aggregated_histories2(all_histories):\n","    # Determine the minimum length of history among all folds\n","    min_length = min(len(hist.history['loss']) for hist in all_histories)\n","\n","    # Truncate all histories to the minimum length\n","    truncated_metric_values = [hist.history['loss'][:min_length] for hist in all_histories]\n","    truncated_val_metric_values = [hist.history['val_loss_fold'][:min_length] for hist in all_histories]\n","\n","    # Calculate the mean and standard deviation for the truncated histories\n","    mean_metric_values = np.mean(truncated_metric_values, axis=0)\n","    mean_val_metric_values = np.mean(truncated_val_metric_values, axis=0)\n","    std_metric_values = np.std(truncated_metric_values, axis=0)\n","    std_val_metric_values = np.std(truncated_val_metric_values, axis=0)\n","\n","    # Plotting\n","    epochs = range(1, min_length + 1)\n","    plt.figure(figsize=(12, 6))\n","\n","    # Plot training metric\n","    plt.plot(epochs, mean_metric_values, label='Mean Training loss')\n","    plt.fill_between(epochs, mean_metric_values - std_metric_values, mean_metric_values + std_metric_values, alpha=0.3, color='blue')  # Fill between the lines with blue color\n","\n","    # Plot validation metric\n","    plt.plot(epochs, mean_val_metric_values, linestyle='dashdot', label='Mean Validation loss')\n","    plt.fill_between(epochs, mean_val_metric_values - std_val_metric_values, mean_val_metric_values + std_val_metric_values, alpha=0.25, color='orange')  # Fill between the lines with orange color\n","\n","    plt.title('Mean Training and Validation Mean Squared Error (MSE) per Epoch in a 5-Fold Cross-Validation')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('MSE')\n","    plt.ylim(0, 100)  # Set the limits of the y-axis\n","    plt.legend()\n","    plt.show()\n"],"metadata":{"id":"iO_ADKe_6e26"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["MEE function"],"metadata":{"id":"grIKoYC7iV7J"}},{"cell_type":"code","source":["def mean_euclidean_error(y_true, y_pred):\n","    return np.mean(np.linalg.norm(y_true - y_pred, axis=1))\n","\n"],"metadata":{"id":"brF0qg7qiR_E"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["List top 10"],"metadata":{"id":"5dKdSYpbKRXx"}},{"cell_type":"code","source":["def print_model_collection(models):\n","    print(\"Top Model Configurations:\")\n","    for i, model in enumerate(models, start=1):\n","        params = model['params']\n","        avg_mse = model['avg_mse']\n","        std_mse = model['std_mse']\n","        print(f\"Model {i}:\")\n","        print(f\"   Average MSE: {avg_mse:.4f}, Std MSE: {std_mse:.4f}\")\n","        for param, value in params.items():\n","            print(f\"   {param}: {value}\")\n","        print()\n","\n"],"metadata":{"id":"lotvoZL3KSwv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Grid Search with batchsize, patience and learning rate reduce"],"metadata":{"id":"DB4TO7epRcqj"}},{"cell_type":"code","source":["def perform_callbacks_grid_search(train_x, train_y, param_grid, fixed_param_grid):\n","    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n","    all_models = []\n","\n","    combination_count = 0  # Initialize combination count\n","\n","    total_combinations = len(param_grid['batch_size']) * len(param_grid['patience_es']) * len(param_grid['patience_lr']) * len(param_grid['factor_lr'])\n","    print(f\"Total Combinations: {total_combinations}\")\n","\n","    for batch_size in param_grid['batch_size']:\n","        for patience_es in param_grid['patience_es']:\n","            for patience_lr in param_grid['patience_lr']:\n","                for factor_lr in param_grid['factor_lr']:\n","                    fold_scores = []\n","                    for train_index, val_index in kf.split(train_x):\n","                        X_train_fold, X_val_fold = train_x.iloc[train_index], train_x.iloc[val_index]\n","                        y_train_fold, y_val_fold = train_y.iloc[train_index], train_y.iloc[val_index]\n","\n","                        scaler = StandardScaler()\n","                        X_train_fold_scaled = scaler.fit_transform(X_train_fold)\n","                        X_val_fold_scaled = scaler.transform(X_val_fold)\n","                        tf.keras.backend.clear_session()\n","                        tf.keras.utils.set_random_seed(42)\n","\n","                        model = create_model(units1=fixed_param_grid['units1'], activation1=fixed_param_grid['activation'], l2_reg1=fixed_param_grid['l2_reg'],\n","                                             units2=fixed_param_grid['units2'], activation2=fixed_param_grid['activation'], l2_reg2=fixed_param_grid['l2_reg'],\n","                                             units3=fixed_param_grid['units3'], activation3=fixed_param_grid['activation'], l2_reg3=fixed_param_grid['l2_reg'],\n","                                             dropout_rate=fixed_param_grid['dropout_rate'], learning_rate=fixed_param_grid['learning_rate'])\n","\n","                        early_stopping = EarlyStopping(monitor='val_loss', patience=patience_es, verbose=0, restore_best_weights=True)\n","                        reduce_lr_on_plateau = ReduceLROnPlateau(monitor='val_loss', factor=factor_lr, patience=patience_lr, verbose=0)\n","\n","                        model.fit(X_train_fold_scaled, y_train_fold, epochs=300, batch_size=batch_size, verbose=0, validation_split=0.1, callbacks=[early_stopping, reduce_lr_on_plateau])\n","\n","                        val_pred = model.predict(X_val_fold_scaled)\n","                        val_mse = mean_squared_error(y_val_fold, val_pred)\n","                        fold_scores.append(val_mse)\n","\n","                    avg_mse = np.mean(fold_scores)\n","                    std_mse = np.std(fold_scores)\n","\n","                    combination_count += 1  # Increment combination count\n","                    print(f\"Combination {combination_count}/{total_combinations}: Batch Size={batch_size}, Patience ES={patience_es}, Patience LR={patience_lr}, Factor LR={factor_lr}, Avg MSE={avg_mse:.4f}, Std MSE={std_mse:.4f}\")\n","\n","                    all_models.append({\n","                        'params': {\n","                            'batch_size': batch_size,\n","                            'patience_es': patience_es,\n","                            'patience_lr': patience_lr,\n","                            'factor_lr': factor_lr\n","                        },\n","                        'avg_mse': avg_mse,\n","                        'std_mse': std_mse\n","                    })\n","\n","    all_models.sort(key=lambda x: x['avg_mse'])\n","    return all_models\n"],"metadata":{"id":"22xP9vRZRj9e"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Define callback for validation set history is cross validation"],"metadata":{"id":"KsfmWf-8I9FN"}},{"cell_type":"code","source":["from tensorflow.keras.callbacks import Callback\n","\n","class AdditionalValidationSets(Callback):\n","    def __init__(self, validation_sets, verbose=0):\n","        super().__init__()\n","        self.validation_sets = validation_sets\n","        self.verbose = verbose\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        logs = logs or {}\n","        for val_set_name, val_data in self.validation_sets.items():\n","            val_X, val_y = val_data\n","            val_loss = self.model.evaluate(val_X, val_y, verbose=self.verbose)\n","\n","            logs[f'val_loss_fold'] = val_loss\n"],"metadata":{"id":"CBT837TcI8op"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"BrWm1zbnI7xw"}},{"cell_type":"markdown","source":["## Local Execution functions\n","Functions used in local executions that we could not use in colab as it did not have scikeras\n","Install scikeras with to use pip install scikeras\n"],"metadata":{"id":"2VbkOC7zuX4K"}},{"cell_type":"code","source":["from scikeras.wrappers import KerasRegressor"],"metadata":{"id":"FbyqXAAYJrpD","colab":{"base_uri":"https://localhost:8080/","height":314},"executionInfo":{"status":"error","timestamp":1706740619781,"user_tz":-60,"elapsed":539,"user":{"displayName":"Giovanni Cupitó","userId":"11305903449971326153"}},"outputId":"bb5a982a-df71-46ec-e52a-695ab6977f71"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'scikeras'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-5d2493418268>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscikeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrappers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKerasRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'scikeras'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","source":["def create_model_base(units1=32, activationf='tanh', initializer1='random_uniform', l2_reg=0.01,\n","                 units2=32, initializer2='random_uniform',\n","                 units3=32, initializer3='random_uniform',\n","                 dropout_rate=0.1, learning_rate=0.01, beta_1=0.9, beta_2=0.999):\n","    model = Sequential()\n","    model.add(Dense(units1, activation=activationf, kernel_initializer=initializer1,\n","                    kernel_regularizer=l2(l2_reg), input_shape=(10,)))  # Adjust the input_shape based on your data\n","    model.add(Dropout(dropout_rate))\n","    model.add(Dense(units2, activation=activationf, kernel_initializer=initializer2,\n","                    kernel_regularizer=l2(l2_reg)))\n","    model.add(Dropout(dropout_rate))\n","    model.add(Dense(units3, activation=activationf, kernel_initializer=initializer3,\n","                    kernel_regularizer=l2(l2_reg)))\n","    model.add(Dense(3, activation='linear'))  # Adjust the output layer based on your requirements\n","    model.compile(optimizer=Adam(learning_rate=learning_rate, beta_1=beta_1, beta_2=beta_2), loss='mean_squared_error')\n","    return model\n"],"metadata":{"id":"nNjLo3HUJmvC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["(Exhaustive)GridSearch cross validation definition"],"metadata":{"id":"HfmGFTAuJmvC"}},{"cell_type":"code","source":["def GridSearchCV_Call(param_grid):\n","  keras_model = KerasRegressor(model=create_model_base, epochs=100, batch_size=64, verbose=0)\n","\n","  # Create a Pipeline\n","  pipeline = Pipeline([\n","      ('scaler', StandardScaler()),\n","      ('model', keras_model)\n","  ])\n","\n","  #pipeline.set_params(model__c= param_dist)\n","  # Initialize RandomizedSearchCV\n","  grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid,\n","                                     cv=5, verbose=19,scoring='neg_mean_squared_error',n_jobs=-1)\n","\n","  # Perform the search (assuming train_x and train_y are already defined)\n","  grid_search.fit(train_x, train_y)\n","  return grid_search"],"metadata":{"id":"Wiyx1j7vJmvD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["RandomGridSearch cross validation definition"],"metadata":{"id":"gZkRj77MJmvD"}},{"cell_type":"code","source":["def RandomizedSearchCV_Call(param_dist,n_iter=60):\n","  keras_model = KerasRegressor(model=create_model, epochs=100, batch_size=64, verbose=0)\n","\n","  # Create a Pipeline\n","  pipeline = Pipeline([\n","      ('scaler', StandardScaler()),\n","      ('model', keras_model)\n","  ])\n","\n","  #pipeline.set_params(model__c= param_dist)\n","  # Initialize RandomizedSearchCV\n","  random_search = RandomizedSearchCV(estimator=pipeline, param_distributions=param_dist,\n","                                    n_iter=n_iter , cv=5, verbose=19, random_state=42,scoring='neg_mean_squared_error')\n","\n","  # Perform the search (assuming train_x and train_y are already defined)\n","  random_search.fit(train_x, train_y)\n","  return random_search"],"metadata":{"id":"1y4muz_7JmvD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Return Top 10 from RandomSearchCV"],"metadata":{"id":"yYyiG9MiJmvD"}},{"cell_type":"code","source":["def listing_top_10(search):\n","  # Retrieve the top 10 models\n","  top_10_indices = np.argsort(-search.cv_results_['mean_test_score'])[:10]\n","  top_10_scores = search.cv_results_['mean_test_score'][top_10_indices]\n","  top_10_std = search.cv_results_['std_test_score'][top_10_indices]\n","  top_10_params = [search.cv_results_['params'][i] for i in top_10_indices]\n","\n","  for score, std, params in zip(top_10_scores, top_10_std, top_10_params):\n","      print(f\"Score: {score}, Std. Dev: {std}, Parameters: {params}\")\n"],"metadata":{"id":"M784kejHJmvD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# GridSearchCV1-2"],"metadata":{"id":"bZQaKf6VQcMn"}},{"cell_type":"markdown","source":["1h 48 min\n","648 combinations"],"metadata":{"id":"6-MWlvfs-pJI"}},{"cell_type":"code","source":["param_grid = {\n","    'units1': [32, 64,128],\n","    'units2': [32, 64,128],\n","    'units3': [32, 64,128],\n","    'activation': ['relu', 'tanh'],\n","    'l2_reg': [0.01, 0.001],\n","    'dropout_rate': [0.1,0.2],\n","    'learning_rate': [0.01,0.002,0.001]\n","}\n","perform_complete_grid_search(train_x, train_y, param_grid)\n","\n","\n"],"metadata":{"id":"siCWmQVmzJkg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["MSE is from average of validation in folds"],"metadata":{"id":"EM6vA_50TfU4"}},{"cell_type":"markdown","source":["1. **Avg MSE: 2.1809, Std MSE: 0.4736**\n","   - Units1: 128, Activation1: relu, L2_reg: 0.01, Units2: 128, Units3: 64, Dropout Rate: 0.1, Learning Rate: 0.01\n","\n","2. **Avg MSE: 2.2610, Std MSE: 0.6313**\n","   - Units1: 128, Activation1: relu, L2_reg: 0.001, Units2: 128, Units3: 64, Dropout Rate: 0.1, Learning Rate: 0.01\n","\n","3. **Avg MSE: 2.3051, Std MSE: 0.3186**\n","   - Units1: 128, Activation1: relu, L2_reg: 0.001, Units2: 128, Units3: 32, Dropout Rate: 0.1, Learning Rate: 0.01\n","\n","4. **Avg MSE: 2.3392, Std MSE: 0.3667**\n","   - Units1: 64, Activation1: relu, L2_reg: 0.001, Units2: 128, Units3: 64, Dropout Rate: 0.1, Learning Rate: 0.01\n","\n","5. **Avg MSE: 2.4518, Std MSE: 0.4152**\n","   - Units1: 64, Activation1: relu, L2_reg: 0.001, Units2: 128, Units3: 32, Dropout Rate: 0.1, Learning Rate: 0.01\n","\n","6. **Avg MSE: 2.5276, Std MSE: 0.4167**\n","   - Units1: 128, Activation1: relu, L2_reg: 0.01, Units2: 128, Units3: 128, Dropout Rate: 0.1, Learning Rate: 0.01\n","\n","7. **Avg MSE: 2.6283, Std MSE: 0.5368**\n","   - Units1: 128, Activation1: relu, L2_reg: 0.001, Units2: 64, Units3: 128, Dropout Rate: 0.1, Learning Rate: 0.01\n","\n","8. **Avg MSE: 2.6486, Std MSE: 0.5313**\n","   - Units1: 64, Activation1: relu, L2_reg: 0.01, Units2: 128, Units3: 32, Dropout Rate: 0.1, Learning Rate: 0.01\n","\n","9. **Avg MSE: 2.6657, Std MSE: 0.6022**\n","   - Units1: 128, Activation1: relu, L2_reg: 0.001, Units2: 128, Units3: 32, Dropout Rate: 0.2, Learning Rate: 0.01\n","\n","10. **Avg MSE: 2.7026, Std MSE: 0.4988**\n","    - Units1: 64, Activation1: relu, L2_reg: 0.01, Units2: 128, Units3: 64, Dropout Rate: 0.1, Learning Rate: 0.01\n"],"metadata":{"id":"4sNQX-SwGElj"}},{"cell_type":"markdown","source":["CPU times: user 40min 54s <br> sys: 2min 12s<br> total: 43min 6s<br>\n","Wall time: 42min 15s<br>\n","Total Combinations: 96\n","\n"],"metadata":{"id":"JIFwr8x2WnSU"}},{"cell_type":"code","source":["%%time\n","param_grid = {\n","    'units1': [128],\n","    'units2': [128],\n","    'units3': [32, 128],  # let us consider variations around the best values\n","    'activation': ['relu'],  # Keeping 'relu' based its the best\n","    'learning_rate': [0.012, 0.014, 0.016, 0.018],  # Narrowing down around 0.001 with slight variations\n","    'dropout_rate': [0.012, 0.016, 0.1, 0.14],  # Expanding slightly around 0.1 to find a sweet spot\n","    'l2_reg': [0.015, 0.005, 0.01],  # Narrowing down around 0.01 with slight variations\n","}\n","top = perform_complete_grid_search(train_x, train_y, param_grid)"],"metadata":{"id":"I7zdy4tyGGtK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print_model_collection(top)"],"metadata":{"id":"xyslLB5DKUlh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["MSE is from average of validation in folds"],"metadata":{"id":"lw1FVLb0TroO"}},{"cell_type":"markdown","source":["# Top 10 models architectures\n","\n","**Model 1:**\n","- Average MSE: 1.3521, Std MSE: 0.2829\n","- units1: 128\n","- activation1: relu\n","- l2_reg: 0.005\n","- units2: 128\n","- activation2: relu\n","- units3: 128\n","- activation3: relu\n","- dropout_rate: 0.012\n","- learning_rate: 0.014\n","\n","**Model 2:**\n","- Average MSE: 1.3935, Std MSE: 0.2708\n","- units1: 128\n","- activation1: relu\n","- l2_reg: 0.01\n","- units2: 128\n","- activation2: relu\n","- units3: 32\n","- activation3: relu\n","- dropout_rate: 0.012\n","- learning_rate: 0.014\n","\n","**Model 3:**\n","- Average MSE: 1.3967, Std MSE: 0.2706\n","- units1: 128\n","- activation1: relu\n","- l2_reg: 0.005\n","- units2: 128\n","- activation2: relu\n","- units3: 32\n","- activation3: relu\n","- dropout_rate: 0.016\n","- learning_rate: 0.012\n","\n","**Model 4:**\n","- Average MSE: 1.4285, Std MSE: 0.4004\n","- units1: 128\n","- activation1: relu\n","- l2_reg: 0.005\n","- units2: 128\n","- activation2: relu\n","- units3: 128\n","- activation3: relu\n","- dropout_rate: 0.016\n","- learning_rate: 0.016\n","\n","**Model 5:**\n","- Average MSE: 1.4374, Std MSE: 0.2155\n","- units1: 128\n","- activation1: relu\n","- l2_reg: 0.01\n","- units2: 128\n","- activation2: relu\n","- units3: 32\n","- activation3: relu\n","- dropout_rate: 0.012\n","- learning_rate: 0.016\n","\n","**Model 6:**\n","- Average MSE: 1.4747, Std MSE: 0.1603\n","- units1: 128\n","- activation1: relu\n","- l2_reg: 0.005\n","- units2: 128\n","- activation2: relu\n","- units3: 32\n","- activation3: relu\n","- dropout_rate: 0.012\n","- learning_rate: 0.014\n","\n","**Model 7:**\n","- Average MSE: 1.4829, Std MSE: 0.3291\n","- units1: 128\n","- activation1: relu\n","- l2_reg: 0.005\n","- units2: 128\n","- activation2: relu\n","- units3: 128\n","- activation3: relu\n","- dropout_rate: 0.012\n","- learning_rate: 0.012\n","\n","**Model 8:**\n","- Average MSE: 1.4889, Std MSE: 0.3523\n","- units1: 128\n","- activation1: relu\n","- l2_reg: 0.005\n","- units2: 128\n","- activation2: relu\n","- units3: 128\n","- activation3: relu\n","- dropout_rate: 0.016\n","- learning_rate: 0.012\n","\n","**Model 9:**\n","- Average MSE: 1.4893, Std MSE: 0.0824\n","- units1: 128\n","- activation1: relu\n","- l2_reg: 0.005\n","- units2: 128\n","- activation2: relu\n","- units3: 32\n","- activation3: relu\n","- dropout_rate: 0.016\n","- learning_rate: 0.014\n","\n","**Model 10:**\n","- Average MSE: 1.4935, Std MSE: 0.1520\n","- units1: 128\n","- activation1: relu\n","- l2_reg: 0.005\n","- units2: 128\n","- activation2: relu\n","- units3: 32\n","- activation3: relu\n","- dropout_rate: 0.012\n","- learning_rate: 0.012\n"],"metadata":{"id":"0Pgo_tLTULmB"}},{"cell_type":"markdown","source":["# GridSearchCV3"],"metadata":{"id":"_Q0l634AKT1m"}},{"cell_type":"markdown","source":["CPU times: user 42min 26s, sys: 2min 30s, total: 44min 57s\n","Wall time: 48min 28s\n","Combinations 54"],"metadata":{"id":"GYhSEuaT4ThS"}},{"cell_type":"code","source":["%%time\n","\n","fixed_param_grid = {\n","    'units1': 128,\n","    'units2': 128,\n","    'units3': 128,\n","    'activation': 'relu',\n","    'l2_reg': 0.005,\n","    'dropout_rate': 0.012,\n","    'learning_rate': 0.014,\n","\n","}\n","\n","param_grid = {\n","    'batch_size': [16,32,64],  # try lower batches sizes than only 64\n","    'patience_es': [10,20],  # Exploring patience for early stopping\n","    'patience_lr': [5,10,15],  # Exploring patience for learning rate reduction\n","    'factor_lr': [0.05,0.1, 0.2]  # Exploring factors for learning rate reduction\n","}\n","\n","# Assuming train_x and train_y are your training features and labels respectively\n","results = perform_callbacks_grid_search(train_x, train_y, param_grid, fixed_param_grid)"],"metadata":{"id":"8VKbZwo8RxcV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print_model_collection(results)"],"metadata":{"id":"VjgK7B9TstXr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["MSE is from average of validation in folds"],"metadata":{"id":"1p_nITrYTtjx"}},{"cell_type":"markdown","source":["# Top Model Batches/Callbacks Configurations\n","\n","* Model 1\n","- Average MSE: 1.0855\n","- Std MSE: 0.2459\n","- Batch Size: 16\n","- Patience for Early Stopping: 20\n","- Patience for Learning Rate Reduction: 10\n","- Learning Rate Reduction Factor: 0.2\n","\n","## Model 2\n","- Average MSE: 1.1456\n","- Std MSE: 0.3840\n","- Batch Size: 16\n","- Patience for Early Stopping: 20\n","- Patience for Learning Rate Reduction: 10\n","- Learning Rate Reduction Factor: 0.1\n","\n","## Model 3\n","- Average MSE: 1.1740\n","- Std MSE: 0.2918\n","- Batch Size: 16\n","- Patience for Early Stopping: 20\n","- Patience for Learning Rate Reduction: 15\n","- Learning Rate Reduction Factor: 0.1\n","\n","## Model 4\n","- Average MSE: 1.2028\n","- Std MSE: 0.3623\n","- Batch Size: 64\n","- Patience for Early Stopping: 20\n","- Patience for Learning Rate Reduction: 15\n","- Learning Rate Reduction Factor: 0.2\n","\n","## Model 5\n","- Average MSE: 1.2644\n","- Std MSE: 0.2890\n","- Batch Size: 16\n","- Patience for Early Stopping: 10\n","- Patience for Learning Rate Reduction: 5\n","- Learning Rate Reduction Factor: 0.2\n","\n","## Model 6\n","- Average MSE: 1.2700\n","- Std MSE: 0.2878\n","- Batch Size: 16\n","- Patience for Early Stopping: 20\n","- Patience for Learning Rate Reduction: 5\n","- Learning Rate Reduction Factor: 0.2\n","\n","## Model 7\n","- Average MSE: 1.3128\n","- Std MSE: 0.3890\n","- Batch Size: 64\n","- Patience for Early Stopping: 20\n","- Patience for Learning Rate Reduction: 15\n","- Learning Rate Reduction Factor: 0.1\n","\n","## Model 8\n","- Average MSE: 1.3249\n","- Std MSE: 0.3849\n","- Batch Size: 32\n","- Patience for Early Stopping: 20\n","- Patience for Learning Rate Reduction: 10\n","- Learning Rate Reduction Factor: 0.2\n","\n","## Model 9\n","- Average MSE: 1.3468\n","- Std MSE: 0.3799\n","- Batch Size: 32\n","- Patience for Early Stopping: 20\n","- Patience for Learning Rate Reduction: 15\n","- Learning Rate Reduction Factor: 0.1\n","\n","## Model 10\n","- Average MSE: 1.3574\n","- Std MSE: 0.5765\n","- Batch Size: 32\n","- Patience for Early Stopping: 20\n","- Patience for Learning Rate Reduction: 10\n","- Learning Rate Reduction Factor: 0.05\n"],"metadata":{"id":"eVss6WGZuZDu"}},{"cell_type":"markdown","source":["# Matrics measure"],"metadata":{"id":"jrpgkSBFhrGk"}},{"cell_type":"markdown","source":["CPU times: user 2min 21s<br> sys: 6.97 <br> total: 2min 28s <br>\n","Wall time: 2min 58s\n"],"metadata":{"id":"oB18MqM_IxTB"}},{"cell_type":"code","source":["%%time\n","model_param_grid = {\n","    'units1': 128,\n","    'units2': 128,\n","    'units3': 128,\n","    'activation': 'relu',\n","    'l2_reg': 0.005,\n","    'dropout_rate': 0.012,\n","    'learning_rate': 0.014,\n","\n","}\n","\n","training_mse_scores = []\n","validation_mse_scores = []\n","training_mee_scores = []\n","validation_mee_scores = []\n","all_histories = []  # To store history objects from each fold\n","\n","data_X = train_x\n","data_y = train_y\n","# Initialize KFold\n","kf = KFold(n_splits=5, shuffle=True, random_state=42)\n","\n","tf.keras.utils.set_random_seed(42)\n","for train_index, val_index in kf.split(data_X):\n","    X_train_fold, X_val_fold = data_X.iloc[train_index], data_X.iloc[val_index]\n","    y_train_fold, y_val_fold = data_y.iloc[train_index], data_y.iloc[val_index]\n","    scaler = StandardScaler()\n","\n","    train_x_scaled = scaler.fit_transform(X_train_fold)\n","    val_scaled = scaler.transform(X_val_fold)#only transform, prevent leakage, use mean and std of training\n","\n","\n","    model = create_model(units1=model_param_grid['units1'], activation1=model_param_grid['activation'], l2_reg1=model_param_grid['l2_reg'],\n","                                             units2=model_param_grid['units2'], activation2=model_param_grid['activation'], l2_reg2=model_param_grid['l2_reg'],\n","                                             units3=model_param_grid['units3'], activation3=model_param_grid['activation'], l2_reg3=model_param_grid['l2_reg'],\n","                                             dropout_rate=model_param_grid['dropout_rate'], learning_rate=model_param_grid['learning_rate'])\n","\n","\n","    early_stopping = EarlyStopping(monitor='val_loss', patience=20, verbose=1, restore_best_weights=True)\n","    reduce_lr_on_plateau = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, verbose=0)\n","    additional_val_sets = {\n","        'second_val_set': (val_scaled, y_val_fold)\n","    }\n","    additional_validation_callback = AdditionalValidationSets(additional_val_sets, verbose=0)\n","\n","    history = model.fit(train_x_scaled, y_train_fold,validation_split=0.1,\n","                        epochs=300, batch_size=16, verbose=1,callbacks=[early_stopping, reduce_lr_on_plateau,additional_validation_callback])\n","    train_pred = model.predict(train_x_scaled)\n","    val_pred = model.predict(val_scaled)\n","\n","    train_mse = mean_squared_error(y_train_fold, train_pred)\n","    val_mse = mean_squared_error(y_val_fold, val_pred)\n","    train_mee = mean_euclidean_error(y_train_fold, train_pred)\n","    val_mee = mean_euclidean_error(y_val_fold, val_pred)\n","\n","\n","    training_mse_scores.append(train_mse)\n","    validation_mse_scores.append(val_mse)\n","    training_mee_scores.append(train_mee)\n","    validation_mee_scores.append(val_mee)\n","    all_histories.append(history)\n","\n","\n","avg_train_mse = np.mean(training_mse_scores)\n","std_train_mse = np.std(training_mse_scores)\n","avg_val_mse = np.mean(validation_mse_scores)\n","std_val_mse = np.std(validation_mse_scores)\n","avg_train_mee = np.mean(training_mee_scores)\n","std_train_mee = np.std(training_mee_scores)\n","avg_val_mee = np.mean(validation_mee_scores)\n","std_val_mee = np.std(validation_mee_scores)\n","\n","print(f\"Training average 5Fold MSE: {avg_train_mse:.4f} stdev: {std_train_mse:.4f}\")\n","print(f\"Validation average 5Fold MSE: {avg_val_mse:.4f} stdev: {std_val_mse:.4f}\")\n","print(f\"Training average 5Fold MEE: {avg_train_mee:.4f} stdev: {std_train_mee:.4f}\")\n","print(f\"Validation average 5Fold MEE: {avg_val_mee:.4f} stdev: {std_val_mee:.4f}\")"],"metadata":{"id":"K-75TPBfhsEB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- Training average 5Fold MSE: 0.4181 stdev: 0.0841\n","- Validation average 5Fold MSE: 1.2359 stdev: 0.3313\n","- Training average 5Fold MEE: 0.9011 stdev: 0.1063\n","- Validation average 5Fold MEE: 1.4002 stdev: 0.1537\n"],"metadata":{"id":"qgNODNDd7rVT"}},{"cell_type":"code","source":["plot_aggregated_histories(all_histories)"],"metadata":{"id":"rlz-zG5cnwjk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_aggregated_histories2(all_histories)"],"metadata":{"id":"nfwfoaJJ6ijj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Final training.\n","We monitor loss on the training set and not the test set for EarlyStopping and ReduceLROnPlateau.\n"],"metadata":{"id":"gIRjP7tgnirv"}},{"cell_type":"code","source":["%%time\n","model_param_grid = {\n","    'units1': 128,\n","    'units2': 128,\n","    'units3': 128,\n","    'activation': 'relu',\n","    'l2_reg': 0.005,\n","    'dropout_rate': 0.012,\n","    'learning_rate': 0.014,\n","\n","}\n","tf.keras.utils.set_random_seed(42)\n","\n","scaler = StandardScaler()\n","train_x_scaled = scaler.fit_transform(train_x)\n","test_scaled = scaler.transform(test_x)#only transform, prevent leakage, use mean and std of training\n","best_model = create_model(units1=model_param_grid['units1'], activation1=model_param_grid['activation'], l2_reg1=model_param_grid['l2_reg'],\n","                                             units2=model_param_grid['units2'], activation2=model_param_grid['activation'], l2_reg2=model_param_grid['l2_reg'],\n","                                             units3=model_param_grid['units3'], activation3=model_param_grid['activation'], l2_reg3=model_param_grid['l2_reg'],\n","                                             dropout_rate=model_param_grid['dropout_rate'], learning_rate=model_param_grid['learning_rate'])\n","early_stopping = EarlyStopping(monitor='val_loss', patience=20, verbose=1, restore_best_weights=True)\n","reduce_lr_on_plateau = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, verbose=0)\n"],"metadata":{"id":"3lDkvC6cjGlL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706740850558,"user_tz":-60,"elapsed":457,"user":{"displayName":"Giovanni Cupitó","userId":"11305903449971326153"}},"outputId":"91da22e7-dd19-4a1b-e408-661fd581ce67"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["CPU times: user 78.9 ms, sys: 3 ms, total: 81.9 ms\n","Wall time: 78.7 ms\n"]}]},{"cell_type":"markdown","source":["CPU times: user 19.8 s, sys: 1.28 s, total: 21.1 s\n","Wall time: 19.4 s\n"],"metadata":{"id":"qnoeUiuYDQDe"}},{"cell_type":"code","source":["%%time\n","tf.keras.utils.set_random_seed(42)\n","history = best_model.fit(train_x_scaled, train_y, validation_split = 0.1,\n","                            epochs=300, batch_size=16, callbacks=[early_stopping, reduce_lr_on_plateau], verbose=1)"],"metadata":{"id":"s5y5tnTWCSBz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706740874414,"user_tz":-60,"elapsed":22050,"user":{"displayName":"Giovanni Cupitó","userId":"11305903449971326153"}},"outputId":"a16f178b-bace-4b02-a755-1fdaff3951d1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/300\n","34/34 [==============================] - 1s 8ms/step - loss: 161.0970 - val_loss: 40.3823 - lr: 0.0140\n","Epoch 2/300\n","34/34 [==============================] - 0s 5ms/step - loss: 43.9605 - val_loss: 41.6479 - lr: 0.0140\n","Epoch 3/300\n","34/34 [==============================] - 0s 5ms/step - loss: 34.6807 - val_loss: 31.8799 - lr: 0.0140\n","Epoch 4/300\n","34/34 [==============================] - 0s 5ms/step - loss: 22.8530 - val_loss: 23.1789 - lr: 0.0140\n","Epoch 5/300\n","34/34 [==============================] - 0s 5ms/step - loss: 16.5511 - val_loss: 16.6560 - lr: 0.0140\n","Epoch 6/300\n","34/34 [==============================] - 0s 5ms/step - loss: 13.3243 - val_loss: 12.1130 - lr: 0.0140\n","Epoch 7/300\n","34/34 [==============================] - 0s 5ms/step - loss: 11.8896 - val_loss: 10.9483 - lr: 0.0140\n","Epoch 8/300\n","34/34 [==============================] - 0s 4ms/step - loss: 10.9948 - val_loss: 10.3704 - lr: 0.0140\n","Epoch 9/300\n","34/34 [==============================] - 0s 4ms/step - loss: 10.6405 - val_loss: 11.3374 - lr: 0.0140\n","Epoch 10/300\n","34/34 [==============================] - 0s 5ms/step - loss: 10.4864 - val_loss: 10.9595 - lr: 0.0140\n","Epoch 11/300\n","34/34 [==============================] - 0s 5ms/step - loss: 10.3035 - val_loss: 10.7932 - lr: 0.0140\n","Epoch 12/300\n","34/34 [==============================] - 0s 4ms/step - loss: 9.6552 - val_loss: 11.4485 - lr: 0.0140\n","Epoch 13/300\n","34/34 [==============================] - 0s 4ms/step - loss: 9.5592 - val_loss: 8.6528 - lr: 0.0140\n","Epoch 14/300\n","34/34 [==============================] - 0s 7ms/step - loss: 9.9857 - val_loss: 13.2310 - lr: 0.0140\n","Epoch 15/300\n","34/34 [==============================] - 0s 12ms/step - loss: 9.3472 - val_loss: 8.9452 - lr: 0.0140\n","Epoch 16/300\n","34/34 [==============================] - 0s 11ms/step - loss: 8.1540 - val_loss: 7.1691 - lr: 0.0140\n","Epoch 17/300\n","34/34 [==============================] - 0s 9ms/step - loss: 7.5556 - val_loss: 8.4004 - lr: 0.0140\n","Epoch 18/300\n","34/34 [==============================] - 0s 9ms/step - loss: 7.5179 - val_loss: 6.3239 - lr: 0.0140\n","Epoch 19/300\n","34/34 [==============================] - 0s 10ms/step - loss: 7.4117 - val_loss: 5.9627 - lr: 0.0140\n","Epoch 20/300\n","34/34 [==============================] - 0s 11ms/step - loss: 6.9898 - val_loss: 6.5261 - lr: 0.0140\n","Epoch 21/300\n","34/34 [==============================] - 0s 9ms/step - loss: 6.8750 - val_loss: 7.1859 - lr: 0.0140\n","Epoch 22/300\n","34/34 [==============================] - 0s 10ms/step - loss: 6.5633 - val_loss: 5.4005 - lr: 0.0140\n","Epoch 23/300\n","34/34 [==============================] - 0s 8ms/step - loss: 5.9521 - val_loss: 4.3307 - lr: 0.0140\n","Epoch 24/300\n","34/34 [==============================] - 0s 10ms/step - loss: 5.7915 - val_loss: 4.5164 - lr: 0.0140\n","Epoch 25/300\n","34/34 [==============================] - 0s 11ms/step - loss: 5.2861 - val_loss: 4.7882 - lr: 0.0140\n","Epoch 26/300\n","34/34 [==============================] - 0s 10ms/step - loss: 5.2152 - val_loss: 4.9036 - lr: 0.0140\n","Epoch 27/300\n","34/34 [==============================] - 0s 15ms/step - loss: 4.8720 - val_loss: 3.8389 - lr: 0.0140\n","Epoch 28/300\n","34/34 [==============================] - 0s 9ms/step - loss: 5.4171 - val_loss: 5.8023 - lr: 0.0140\n","Epoch 29/300\n","34/34 [==============================] - 0s 14ms/step - loss: 5.5753 - val_loss: 4.8618 - lr: 0.0140\n","Epoch 30/300\n","34/34 [==============================] - 0s 14ms/step - loss: 5.7611 - val_loss: 5.3482 - lr: 0.0140\n","Epoch 31/300\n","34/34 [==============================] - 1s 16ms/step - loss: 5.2046 - val_loss: 3.7275 - lr: 0.0140\n","Epoch 32/300\n","34/34 [==============================] - 0s 12ms/step - loss: 5.5248 - val_loss: 6.6994 - lr: 0.0140\n","Epoch 33/300\n","34/34 [==============================] - 0s 9ms/step - loss: 5.3518 - val_loss: 4.4304 - lr: 0.0140\n","Epoch 34/300\n","34/34 [==============================] - 0s 5ms/step - loss: 5.8664 - val_loss: 7.6168 - lr: 0.0140\n","Epoch 35/300\n","34/34 [==============================] - 0s 4ms/step - loss: 6.9826 - val_loss: 4.3722 - lr: 0.0140\n","Epoch 36/300\n","34/34 [==============================] - 0s 4ms/step - loss: 7.4896 - val_loss: 9.3157 - lr: 0.0140\n","Epoch 37/300\n","34/34 [==============================] - 0s 5ms/step - loss: 7.4643 - val_loss: 7.4901 - lr: 0.0140\n","Epoch 38/300\n","34/34 [==============================] - 0s 5ms/step - loss: 7.8843 - val_loss: 8.9533 - lr: 0.0140\n","Epoch 39/300\n","34/34 [==============================] - 0s 5ms/step - loss: 8.4536 - val_loss: 6.7522 - lr: 0.0140\n","Epoch 40/300\n","34/34 [==============================] - 0s 5ms/step - loss: 7.2784 - val_loss: 6.0006 - lr: 0.0140\n","Epoch 41/300\n","34/34 [==============================] - 0s 5ms/step - loss: 6.8119 - val_loss: 5.4723 - lr: 0.0140\n","Epoch 42/300\n","34/34 [==============================] - 0s 5ms/step - loss: 5.3283 - val_loss: 4.4007 - lr: 0.0028\n","Epoch 43/300\n","34/34 [==============================] - 0s 4ms/step - loss: 4.3756 - val_loss: 3.5167 - lr: 0.0028\n","Epoch 44/300\n","34/34 [==============================] - 0s 5ms/step - loss: 4.2381 - val_loss: 4.9836 - lr: 0.0028\n","Epoch 45/300\n","34/34 [==============================] - 0s 5ms/step - loss: 3.6932 - val_loss: 3.9178 - lr: 0.0028\n","Epoch 46/300\n","34/34 [==============================] - 0s 4ms/step - loss: 3.6320 - val_loss: 3.1027 - lr: 0.0028\n","Epoch 47/300\n","34/34 [==============================] - 0s 5ms/step - loss: 3.5208 - val_loss: 3.2989 - lr: 0.0028\n","Epoch 48/300\n","34/34 [==============================] - 0s 5ms/step - loss: 3.4558 - val_loss: 3.0856 - lr: 0.0028\n","Epoch 49/300\n","34/34 [==============================] - 0s 5ms/step - loss: 3.1134 - val_loss: 3.2884 - lr: 0.0028\n","Epoch 50/300\n","34/34 [==============================] - 0s 5ms/step - loss: 2.8694 - val_loss: 2.6389 - lr: 0.0028\n","Epoch 51/300\n","34/34 [==============================] - 0s 4ms/step - loss: 3.0873 - val_loss: 3.4514 - lr: 0.0028\n","Epoch 52/300\n","34/34 [==============================] - 0s 4ms/step - loss: 3.2751 - val_loss: 2.7676 - lr: 0.0028\n","Epoch 53/300\n","34/34 [==============================] - 0s 4ms/step - loss: 2.9356 - val_loss: 2.6043 - lr: 0.0028\n","Epoch 54/300\n","34/34 [==============================] - 0s 4ms/step - loss: 3.0155 - val_loss: 2.8934 - lr: 0.0028\n","Epoch 55/300\n","34/34 [==============================] - 0s 4ms/step - loss: 2.6653 - val_loss: 2.9828 - lr: 0.0028\n","Epoch 56/300\n","34/34 [==============================] - 0s 5ms/step - loss: 2.7384 - val_loss: 2.8598 - lr: 0.0028\n","Epoch 57/300\n","34/34 [==============================] - 0s 4ms/step - loss: 2.9040 - val_loss: 2.5726 - lr: 0.0028\n","Epoch 58/300\n","34/34 [==============================] - 0s 5ms/step - loss: 3.0652 - val_loss: 2.5896 - lr: 0.0028\n","Epoch 59/300\n","34/34 [==============================] - 0s 5ms/step - loss: 3.1618 - val_loss: 3.4393 - lr: 0.0028\n","Epoch 60/300\n","34/34 [==============================] - 0s 5ms/step - loss: 2.9951 - val_loss: 2.4350 - lr: 0.0028\n","Epoch 61/300\n","34/34 [==============================] - 0s 5ms/step - loss: 2.7795 - val_loss: 3.4477 - lr: 0.0028\n","Epoch 62/300\n","34/34 [==============================] - 0s 5ms/step - loss: 2.9496 - val_loss: 2.3840 - lr: 0.0028\n","Epoch 63/300\n","34/34 [==============================] - 0s 4ms/step - loss: 2.8159 - val_loss: 2.3929 - lr: 0.0028\n","Epoch 64/300\n","34/34 [==============================] - 0s 4ms/step - loss: 2.7750 - val_loss: 3.1241 - lr: 0.0028\n","Epoch 65/300\n","34/34 [==============================] - 0s 4ms/step - loss: 2.7877 - val_loss: 2.0588 - lr: 0.0028\n","Epoch 66/300\n","34/34 [==============================] - 0s 5ms/step - loss: 2.4379 - val_loss: 2.4331 - lr: 0.0028\n","Epoch 67/300\n","34/34 [==============================] - 0s 4ms/step - loss: 2.3230 - val_loss: 2.4153 - lr: 0.0028\n","Epoch 68/300\n","34/34 [==============================] - 0s 4ms/step - loss: 2.4343 - val_loss: 2.3023 - lr: 0.0028\n","Epoch 69/300\n","34/34 [==============================] - 0s 5ms/step - loss: 2.3837 - val_loss: 2.2656 - lr: 0.0028\n","Epoch 70/300\n","34/34 [==============================] - 0s 4ms/step - loss: 2.4985 - val_loss: 2.7005 - lr: 0.0028\n","Epoch 71/300\n","34/34 [==============================] - 0s 4ms/step - loss: 2.4271 - val_loss: 2.4327 - lr: 0.0028\n","Epoch 72/300\n","34/34 [==============================] - 0s 5ms/step - loss: 2.5394 - val_loss: 2.2668 - lr: 0.0028\n","Epoch 73/300\n","34/34 [==============================] - 0s 4ms/step - loss: 2.4114 - val_loss: 2.3294 - lr: 0.0028\n","Epoch 74/300\n","34/34 [==============================] - 0s 4ms/step - loss: 2.5006 - val_loss: 2.2892 - lr: 0.0028\n","Epoch 75/300\n","34/34 [==============================] - 0s 5ms/step - loss: 2.5162 - val_loss: 2.1327 - lr: 0.0028\n","Epoch 76/300\n","34/34 [==============================] - 0s 5ms/step - loss: 2.3861 - val_loss: 2.1808 - lr: 5.6000e-04\n","Epoch 77/300\n","34/34 [==============================] - 0s 4ms/step - loss: 2.3317 - val_loss: 2.1228 - lr: 5.6000e-04\n","Epoch 78/300\n","34/34 [==============================] - 0s 4ms/step - loss: 2.1959 - val_loss: 1.9965 - lr: 5.6000e-04\n","Epoch 79/300\n","34/34 [==============================] - 0s 5ms/step - loss: 2.0292 - val_loss: 2.1074 - lr: 5.6000e-04\n","Epoch 80/300\n","34/34 [==============================] - 0s 5ms/step - loss: 2.1498 - val_loss: 2.1195 - lr: 5.6000e-04\n","Epoch 81/300\n","34/34 [==============================] - 0s 5ms/step - loss: 2.1004 - val_loss: 2.2645 - lr: 5.6000e-04\n","Epoch 82/300\n","34/34 [==============================] - 0s 5ms/step - loss: 2.1147 - val_loss: 2.0342 - lr: 5.6000e-04\n","Epoch 83/300\n","34/34 [==============================] - 0s 4ms/step - loss: 2.1034 - val_loss: 2.0299 - lr: 5.6000e-04\n","Epoch 84/300\n","34/34 [==============================] - 0s 5ms/step - loss: 2.1609 - val_loss: 2.1545 - lr: 5.6000e-04\n","Epoch 85/300\n","34/34 [==============================] - 0s 4ms/step - loss: 1.9743 - val_loss: 2.1288 - lr: 5.6000e-04\n","Epoch 86/300\n","34/34 [==============================] - 0s 5ms/step - loss: 2.1047 - val_loss: 2.0059 - lr: 5.6000e-04\n","Epoch 87/300\n","34/34 [==============================] - 0s 4ms/step - loss: 2.0641 - val_loss: 2.1525 - lr: 5.6000e-04\n","Epoch 88/300\n","34/34 [==============================] - 0s 4ms/step - loss: 2.1182 - val_loss: 2.0739 - lr: 5.6000e-04\n","Epoch 89/300\n","34/34 [==============================] - 0s 5ms/step - loss: 2.1870 - val_loss: 2.0619 - lr: 1.1200e-04\n","Epoch 90/300\n","34/34 [==============================] - 0s 4ms/step - loss: 2.1632 - val_loss: 2.0975 - lr: 1.1200e-04\n","Epoch 91/300\n","34/34 [==============================] - 0s 6ms/step - loss: 2.1976 - val_loss: 2.1122 - lr: 1.1200e-04\n","Epoch 92/300\n","34/34 [==============================] - 0s 6ms/step - loss: 2.1417 - val_loss: 2.0850 - lr: 1.1200e-04\n","Epoch 93/300\n","34/34 [==============================] - 0s 6ms/step - loss: 2.2629 - val_loss: 2.0703 - lr: 1.1200e-04\n","Epoch 94/300\n","34/34 [==============================] - 0s 6ms/step - loss: 2.3207 - val_loss: 2.0604 - lr: 1.1200e-04\n","Epoch 95/300\n","34/34 [==============================] - 0s 7ms/step - loss: 2.0301 - val_loss: 2.0738 - lr: 1.1200e-04\n","Epoch 96/300\n","34/34 [==============================] - 0s 6ms/step - loss: 2.1799 - val_loss: 2.0775 - lr: 1.1200e-04\n","Epoch 97/300\n","34/34 [==============================] - 0s 7ms/step - loss: 2.0990 - val_loss: 2.0885 - lr: 1.1200e-04\n","Epoch 98/300\n","31/34 [==========================>...] - ETA: 0s - loss: 2.1762Restoring model weights from the end of the best epoch: 78.\n","34/34 [==============================] - 0s 7ms/step - loss: 2.1681 - val_loss: 2.0575 - lr: 1.1200e-04\n","Epoch 98: early stopping\n","CPU times: user 19.2 s, sys: 1.31 s, total: 20.5 s\n","Wall time: 21.8 s\n"]}]},{"cell_type":"code","source":["best_model.save(\"./bestmodelobtained\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706459123676,"user_tz":-60,"elapsed":3851,"user":{"displayName":"CALOGERO TURCO","userId":"08566164267691496648"}},"outputId":"6a3fc5c9-1c64-4a93-ead9-9b7f755a5801","id":"fQSP_aqDjGlL"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: ./bestmodelobtained/assets\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Assets written to: ./bestmodelobtained/assets\n"]}]},{"cell_type":"code","source":["best_model = tf.keras.models.load_model('./bestmodelobtained')"],"metadata":{"id":"AveONjn5ahr8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["scaler = StandardScaler()\n","train_x_scaled = scaler.fit_transform(train_x)\n","test_x_scaled = scaler.transform(test_x)#only transform, prevent leakage, use mean and std of training\n","\n","# Predict labels for the training set\n","train_labels_pred = best_model.predict(train_x_scaled)\n","\n","# Predict labels for the test set\n","test_labels_pred = best_model.predict(test_x_scaled)\n","\n","# Calculate MSE for the training set\n","train_mse = mean_squared_error(train_y, train_labels_pred)\n","print(f\"Training MSE: {train_mse}\")\n","\n","# Calculate MSE for the test set\n","test_mse = mean_squared_error(test_y, test_labels_pred)\n","print(f\"Test MSE: {test_mse}\")\n","\n","# Calculate MEE for the training set\n","train_mee = mean_euclidean_error(train_y, train_labels_pred)\n","print(f\"Training MEE: {train_mee}\")\n","\n","# Calculate MEE for the test set\n","test_mee = mean_euclidean_error(test_y, test_labels_pred)\n","print(f\"Test MEE: {test_mee}\")\n"],"metadata":{"id":"TE0e8Oa7jGlM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- Training MSE: 0.4488829589086582\n","- Test MSE: 1.5597875299329342\n","- Training MEE: 0.9347387567697988\n","- Test MEE: 1.7609950973231525\n"],"metadata":{"id":"UxhRPO8mqD2m"}},{"cell_type":"code","source":["best_model = tf.keras.models.load_model('./bestmodelobtained')"],"metadata":{"id":"ke7AXVToavPg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(12, 6))\n","plt.subplot(1, 2, 1)\n","plt.scatter(test_y, test_labels_pred)\n","plt.title(\"Best model of NN on Test Set - Predicted vs Actual\")\n","plt.xlabel(\"Actual Values\")\n","plt.ylabel(\"Predicted Values\")"],"metadata":{"id":"yzZgby7paEZe"},"execution_count":null,"outputs":[]}]}
