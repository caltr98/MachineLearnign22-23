{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from keras.models import Sequential\n","from keras.layers import Dense, BatchNormalization, Dropout\n","from keras.optimizers import Adam, SGD, RMSprop, Adadelta, Adagrad, Adamax, Nadam, Ftrl\n","from keras.callbacks import EarlyStopping, ModelCheckpoint\n","#from keras.wrappers.scikit_learn import KerasClassifier\n","from sklearn.model_selection import GridSearchCV\n","import math\n","from sklearn.metrics import make_scorer, accuracy_score\n","\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import cross_val_score\n","\n","from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, LeakyReLU\n","from tensorflow.keras.optimizers import SGD\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.callbacks import LearningRateScheduler\n","from tensorflow.keras import initializers\n","\n","from matplotlib import pyplot\n","from sklearn.metrics import make_scorer, accuracy_score\n","from sklearn.model_selection import StratifiedKFold\n","from keras.layers import LeakyReLU\n","#LeakyReLU = LeakyReLU(alpha=0.1)\n","import warnings\n","warnings.filterwarnings('ignore')\n","pd.set_option(\"display.max_columns\", None)"],"metadata":{"id":"o1yZXGsjqF3r","executionInfo":{"status":"ok","timestamp":1707153076444,"user_tz":-60,"elapsed":15769,"user":{"displayName":"GIOVANNI CUPITO'","userId":"13709433079292750140"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["# One-h-k"],"metadata":{"id":"FENVZXz_qGUo"}},{"cell_type":"code","source":["def one_hot_encode(dataset, variables):\n","    for variable in variables:\n","        dummies = pd.get_dummies(dataset[variable], prefix=variable).astype(int)\n","        dataset = pd.concat([dataset, dummies], axis=1)\n","        dataset.drop(columns=[variable], inplace=True)\n","    return dataset"],"metadata":{"id":"O5IbZrv1qQt3","executionInfo":{"status":"ok","timestamp":1707153448838,"user_tz":-60,"elapsed":13,"user":{"displayName":"GIOVANNI CUPITO'","userId":"13709433079292750140"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"P3lywC0hRmmX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Search Function"],"metadata":{"id":"pCJkXkQCR1qw"}},{"cell_type":"code","source":["def search(x_tr, y_tr, x_vl, y_vl, lr, functions1, functions2, batch_size, units, epochs):\n","    # Record the best score and corresponding hyperparameters\n","    best_score = None\n","    best_params = {}\n","    best_model_1 = None\n","    best_accuracy = None\n","\n","    # Manual grid search\n","    for lr_temp in lr:\n","        for n_unit in units:\n","            for function_temp1 in functions1:\n","                for function_temp2 in functions2:\n","                    for bs_temp in batch_size:\n","                        # Build the model\n","                        model = Sequential()\n","                        model.add(Dense(n_unit, input_shape=(x_tr.shape[1],), activation=function_temp1, kernel_initializer=initializers.glorot_uniform(seed=0)))  # primo livello che ha il numero di neuroni (4) uguale al numero di input features. poi viene specificato il numero delle colonne input\n","                        model.add(Dense(1, activation=function_temp2))  # secondo layer un solo neurone per task di classificazione\n","\n","                        opt = tf.keras.optimizers.Adam(lr_temp)\n","                        model.compile(loss='mean_squared_error', optimizer=opt, metrics=['accuracy'])\n","                        history = model.fit(\n","                            x_tr, y_tr,\n","                            epochs=epochs,\n","                            batch_size=bs_temp,\n","                            verbose=1\n","                        )\n","\n","                        # Evaluate the model\n","                        loss_tr, accuracy_tr = model.evaluate(x_tr, y_tr, verbose=0)\n","                        loss_vl, accuracy_vl = model.evaluate(x_vl, y_vl, verbose=0)\n","\n","                        # Update best score and parameters if the current model is better\n","                        if best_accuracy is None or (accuracy_vl > best_accuracy):\n","                            best_accuracy = accuracy_vl\n","                            best_params = {\n","                                'learning_rate': lr_temp,\n","                                'batch_size': bs_temp,\n","                                'function1': function_temp1,\n","                                'function2': function_temp2,\n","                                'n_units': n_unit\n","                            }\n","                            best_accuracy_vl = accuracy_vl\n","                            best_accuracy_tr = accuracy_tr\n","                            best_loss_tr = loss_tr\n","                            best_loss_vl = loss_vl\n","\n","    print(\"Best hyperparameters:\")\n","    print(best_params)\n","    print('Best accuracy  tr', best_accuracy_tr)\n","    print('Best accuracy  vl', best_accuracy_vl)\n","    print('Best loss tr', best_loss_tr)\n","    print('Best loss  vl', best_loss_vl)\n","\n","    return best_params\n"],"metadata":{"id":"jT64iwejSvLz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# MONK 1"],"metadata":{"id":"zAUJiy3DqG8y"}},{"cell_type":"code","source":["df = pd.read_csv('MONK/monks-1.train', delim_whitespace=True, low_memory=False, header = None, names = ['y',1,2,3,4,5,6], usecols=[0,1,2,3,4,5,6])\n","df_2 = pd.read_csv('MONK/monks-1.test', delim_whitespace=True, low_memory=False, header = None, names = ['y',1,2,3,4,5,6], usecols=[0,1,2,3,4,5,6])\n","#124 righe df\n","#432 righe df_2"],"metadata":{"id":"ymMjVIhzqStJ","executionInfo":{"status":"ok","timestamp":1707153543045,"user_tz":-60,"elapsed":11,"user":{"displayName":"GIOVANNI CUPITO'","userId":"13709433079292750140"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["## Applicazione one hot encoding"],"metadata":{"id":"Fc0dg9Y6qTsY"}},{"cell_type":"code","source":["monk1_tr=one_hot_encode(df, [1,2,3,4,5,6])\n","monk1_ts=one_hot_encode(df_2, [1,2,3,4,5,6])"],"metadata":{"id":"lY2Yc1kgqUna","executionInfo":{"status":"ok","timestamp":1707153583542,"user_tz":-60,"elapsed":17,"user":{"displayName":"GIOVANNI CUPITO'","userId":"13709433079292750140"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["## Split dataset"],"metadata":{"id":"P5HR9eVS3bKJ"}},{"cell_type":"code","source":["training_1_x, validation_1_x, training_1_y, validation_1_y = train_test_split(monk1_tr, df[['y']], stratify =None, test_size=0.30, random_state = 42, shuffle=False)"],"metadata":{"id":"m9GxYzX3iz1q","executionInfo":{"status":"ok","timestamp":1707153888456,"user_tz":-60,"elapsed":8,"user":{"displayName":"GIOVANNI CUPITO'","userId":"13709433079292750140"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["x_1_ts = monk1_ts.iloc[:,1:].values #ottiene tutte le colonne con indice >=1, scartando la target label\n","y_1_ts = monk1_ts.iloc[:,0].values # ottiene solo colonne con indice 0, solo la target label\n","x_1_tr = training_1_x.iloc[:,1:].values\n","y_1_tr = training_1_y.iloc[:,:].values\n","x_1_vl = validation_1_x.iloc[:,1:].values\n","y_1_vl = validation_1_y.iloc[:,:].values\n","\n","x_1_ds = monk1_tr.iloc[:,1:].values\n","y_1_ds = monk1_tr.iloc[:,0].values"],"metadata":{"id":"9x2kJjVPqXho"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##  Search"],"metadata":{"id":"K-ocJ9it3gix"}},{"cell_type":"code","source":["%%time\n","\n","# Define hyperparameters to search\n","lr = [0.002, 0.006, 0.008]\n","functions1 = ['tanh', 'sigmoid']\n","functions2 = ['tanh', 'sigmoid','softmax']\n","\n","batch_size = [4,8,12]\n","units = [4]\n","\n","best_params_monk1 = search(x_tr=x_1_tr ,y_tr=y_1_tr, x_vl=x_1_vl,y_vl=y_1_vl, lr=lr, functions1= functions1,functions2=functions2, batch_size= batch_size, units= units, epochs= 80)"],"metadata":{"id":"RzT9_PaNP1u2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["best_model = Sequential()\n","best_model.add(Dense(best_params_monk1['n_units'], input_shape=(x_1_tr.shape[1],), activation=best_params_monk1['function1'],kernel_initializer=initializers.glorot_uniform(seed=0))) # primo livello che ha il numero di neuroni (4) uguale al numero di                                                                          # input features. poi viene specificato il numero delle colonne input\n","best_model.add(Dense(1, activation= best_params_monk1['function2'])) # secondo layer un solo neurone per task di classificazione\n","\n","opt = tf.keras.optimizers.Adam(best_params_monk1['learning_rate'])\n","best_model.compile(loss='mean_squared_error', optimizer = opt, metrics=['accuracy'])\n","history_best = best_model.fit(\n","              x_1_ds, y_1_ds, validation_data=(x_1_ts,y_1_ts),\n","              epochs=80,\n","              batch_size= best_params_monk1['batch_size'], verbose=2\n","          )\n","\n","training_mse,training_accuracy = best_model.evaluate(x_1_ds, y_1_ds, verbose=0)\n","test_mse,test_accuracy = best_model.evaluate(x_1_ts, y_1_ts,verbose=0)\n","print('Training MSE: %.6f Test MSE: %.6f'%(training_mse,test_mse))\n","print('Training accuracy: %.4f Test accuracy: %.4f'%(training_accuracy,test_accuracy))\n","\n"],"metadata":{"id":"ks5WQgv3JBsV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Risultati"],"metadata":{"id":"IQrftB3M3mDq"}},{"cell_type":"code","source":["print('Training MSE: %.6f Test MSE: %.6f'%(training_mse,test_mse))\n","print('Training accuracy: %.4f Test accuracy: %.4f'%(training_accuracy,test_accuracy))\n","pyplot.title('MONK 1')\n","pyplot.plot(history_best.history['loss'], label='training')\n","pyplot.plot(history_best.history['val_loss'], label='test',linestyle=\"dashed\")\n","pyplot.xlabel('epoch')\n","pyplot.ylabel('MSE')\n","pyplot.legend()\n","pyplot.show()"],"metadata":{"id":"WUDVNsPtqd44"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pyplot.title('MONK 1 ACCURACY')\n","pyplot.plot(history_best.history['accuracy'], label='train')\n","pyplot.plot(history_best.history['val_accuracy'], label='test',linestyle=\"dashed\")\n","pyplot.xlabel('epoch')\n","pyplot.ylabel('ACCURACY')\n","pyplot.legend()\n","pyplot.show()"],"metadata":{"id":"PzXDWKhlwOli"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","best_model.fit(x_1_tr, y_1_tr)\n","predictions = best_model.predict(x_1_ts)\n","# Plot for the first model\n","plt.figure(figsize=(12, 6))\n","plt.subplot(1, 2, 1)\n","plt.scatter(y_1_ts, predictions)\n","plt.title(\"Model GridSearch - Predicted vs Actual\")\n","plt.xlabel(\"Actual Values\")\n","plt.ylabel(\"Predicted Values\")\n","\n","\n","plt.show()\n"],"metadata":{"id":"137vGUE0YCf8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# MONK 2"],"metadata":{"id":"Ts4P5smVqg8e"}},{"cell_type":"code","source":["df = pd.read_csv('MONK/monks-2.train', delim_whitespace=True, low_memory=False, header = None, names = ['y',1,2,3,4,5,6], usecols=[0,1,2,3,4,5,6])\n","df_2 = pd.read_csv('MONK/monks-2.test', delim_whitespace=True, low_memory=False, header = None, names = ['y',1,2,3,4,5,6], usecols=[0,1,2,3,4,5,6])\n"],"metadata":{"id":"nUilfuHjqh2J"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Applicazione one hot encoding e split dataset"],"metadata":{"id":"gT1V3HZYqjtO"}},{"cell_type":"code","source":["monk2_tr=one_hot_encode(df, [1,2,3,4,5,6])\n","monk2_ts=one_hot_encode(df_2, [1,2,3,4,5,6])\n","training_2_x, validation_2_x, training_2_y, validation_2_y = train_test_split(monk2_tr, df[['y']], stratify =None, test_size=0.30, random_state = 42, shuffle=False)\n","\n","x_2_ts = monk2_ts.iloc[:,1:].values #ottiene tutte le colonne con indice >=1, scartando la target label\n","y_2_ts = monk2_ts.iloc[:,0].values # ottiene solo colonne con indice 0, solo la target label\n","\n","x_2_tr = training_2_x.iloc[:,1:].values\n","y_2_tr = training_2_y.iloc[:,:].values\n","x_2_vl = validation_2_x.iloc[:,1:].values\n","y_2_vl = validation_2_y.iloc[:,:].values\n","\n","x_2_ds = monk2_tr.iloc[:,1:].values\n","y_2_ds = monk2_tr.iloc[:,0].values\n"],"metadata":{"id":"y6eoHcV0qiV1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##  Search"],"metadata":{"id":"5535sOPN3wo3"}},{"cell_type":"code","source":["%%time\n","# Define hyperparameters to search\n","lr = [0.002, 0.008, 0.01]\n","functions1 = ['tanh', 'sigmoid']\n","functions2 = ['tanh', 'sigmoid','softmax']\n","batch_size = [4,8,12]\n","units = [4]\n","\n","best_params_monk2 = search(x_tr=x_2_tr ,y_tr=y_2_tr, x_vl=x_2_vl,y_vl=y_2_vl, lr=lr,functions1= functions1,functions2=functions2, batch_size= batch_size, units= units, epochs= 40)\n"],"metadata":{"id":"qaWnxX6Ss0ZB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["best_model = Sequential()\n","best_model.add(Dense(best_params_monk2['n_units'], input_shape=(x_2_tr.shape[1],), activation=best_params_monk2['function1'],kernel_initializer=initializers.glorot_uniform(seed=0))) # primo livello che ha il numero di neuroni (4) uguale al numero di                                                                          # input features. poi viene specificato il numero delle colonne input\n","best_model.add(Dense(1, activation= best_params_monk2['function2'])) # secondo layer un solo neurone per task di classificazione\n","\n","opt = tf.keras.optimizers.Adam(best_params_monk2['learning_rate'])\n","best_model.compile(loss='mean_squared_error', optimizer = opt, metrics=['accuracy'])\n","history_best_2 = best_model.fit(\n","              x_2_ds, y_2_ds, validation_data=(x_2_ts,y_2_ts),\n","              epochs=40,\n","              batch_size= best_params_monk2['batch_size'], verbose=2\n","          )\n","\n","training_mse_2,training_accuracy_2 = best_model.evaluate(x_2_ds, y_2_ds, verbose=0)\n","test_mse_2,test_accuracy_2 = best_model.evaluate(x_2_ts, y_2_ts,verbose=0)\n","print('Training MSE: %.6f Test MSE: %.6f'%(training_mse_2,test_mse_2))\n","print('Training accuracy: %.4f Test accuracy: %.4f'%(training_accuracy_2,test_accuracy_2))\n","\n"],"metadata":{"id":"B0WWVbNtUtOG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Risultati"],"metadata":{"id":"kp-2ehiI34XS"}},{"cell_type":"code","source":["\n","print('Training MSE: %.6f Test MSE: %.6f'%(training_mse_2,test_mse_2))\n","print('Training accuracy: %.4f Test accuracy: %.4f'%(training_accuracy_2,test_accuracy_2))\n","pyplot.title('MONK 2')\n","pyplot.plot(history_best_2.history['loss'], label='training')\n","pyplot.plot(history_best_2.history['val_loss'], label='test',linestyle=\"dashed\")\n","pyplot.xlabel('epoch')\n","pyplot.ylabel('MSE')\n","pyplot.legend()\n","pyplot.show()\n"],"metadata":{"id":"fk7beLH2qpAw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Evaluate model\n","print('Training MSE: %.6f Test MSE: %.6f'%(training_mse_2,test_mse_2))\n","print('Training accuracy: %.4f Test accuracy: %.4f'%(training_accuracy_2,test_accuracy_2))\n","pyplot.title('MONK 2 ACCURACY')\n","pyplot.plot(history_best_2.history['accuracy'], label='training')\n","pyplot.plot(history_best_2.history['val_accuracy'], label='test',linestyle=\"dashed\")\n","pyplot.xlabel('epoch')\n","pyplot.ylabel('MSE')\n","pyplot.legend()\n","pyplot.show()\n"],"metadata":{"id":"T_HlRoZQx1ks"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# MONK 3"],"metadata":{"id":"jBjuU_tQZXgh"}},{"cell_type":"code","source":["df = pd.read_csv('MONK/monks-3.train', delim_whitespace=True, low_memory=False, header = None, names = ['y',1,2,3,4,5,6], usecols=[0,1,2,3,4,5,6])\n","df_2 = pd.read_csv('MONK/monks-3.test', delim_whitespace=True, low_memory=False, header = None, names = ['y',1,2,3,4,5,6], usecols=[0,1,2,3,4,5,6])\n"],"metadata":{"id":"MVIAtRDPZZZc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Applicazione one hot encoding e split dataset"],"metadata":{"id":"nEK02uQj38TB"}},{"cell_type":"code","source":["monk3_tr=one_hot_encode(df, [1,2,3,4,5,6])\n","monk3_ts=one_hot_encode(df_2, [1,2,3,4,5,6])\n","training_3_x, validation_3_x, training_3_y, validation_3_y = train_test_split(monk3_tr, df[['y']], stratify =None, test_size=0.30, random_state = 42, shuffle=False)\n","\n","x_3_ts = monk3_ts.iloc[:,1:].values #ottiene tutte le colonne con indice >=1, scartando la target label\n","y_3_ts = monk3_ts.iloc[:,0].values # ottiene solo colonne con indice 0, solo la target label\n","\n","\n","x_3_tr = training_3_x.iloc[:,1:].values\n","y_3_tr = training_3_y.iloc[:,:].values\n","x_3_vl = validation_3_x.iloc[:,1:].values\n","y_3_vl = validation_3_y.iloc[:,:].values\n","\n","x_3_ds = monk3_tr.iloc[:,1:].values\n","y_3_ds = monk3_tr.iloc[:,0].values\n","\n"],"metadata":{"id":"1vMSvI-9ZaNf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##  Search"],"metadata":{"id":"xmKOF6z_4AwP"}},{"cell_type":"code","source":["%%time\n","\n","# Define hyperparameters to search\n","lr = [0.02, 0.005, 0.01]\n","momentum = [0] # use higher on start of net (usually done!)\n","functions1 = ['tanh', 'sigmoid']\n","functions2 = ['tanh', 'sigmoid','softmax']\n","batch_size = [4,8,12,16]\n","units = [4,8]\n","\n","best_params_monk3 = search(x_tr=x_3_tr ,y_tr=y_3_tr, x_vl=x_3_vl,y_vl=y_3_vl, lr=lr, functions1= functions1,functions2=functions2, batch_size= batch_size, units= units, epochs= 50)\n"],"metadata":{"id":"haYpAfMnw0qc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["best_model = Sequential()\n","best_model.add(Dense(best_params_monk3['n_units'], input_shape=(x_3_tr.shape[1],), activation=best_params_monk3['function1'],kernel_initializer=initializers.glorot_uniform(seed=0))) # primo livello che ha il numero di neuroni (4) uguale al numero di                                                                          # input features. poi viene specificato il numero delle colonne input\n","best_model.add(Dense(1, activation= best_params_monk3['function2'])) # secondo layer un solo neurone per task di classificazione\n","\n","opt = tf.keras.optimizers.Adam(best_params_monk3['learning_rate'])\n","best_model.compile(loss='mean_squared_error', optimizer = opt, metrics=['accuracy'])\n","history_best_3 = best_model.fit(\n","              x_3_ds, y_3_ds, validation_data=(x_3_ts,y_3_ts),\n","              epochs=50,\n","              batch_size= best_params_monk3['batch_size'], verbose=2\n","          )\n","\n","training_mse_3,training_accuracy_3 = best_model.evaluate(x_3_ds, y_3_ds, verbose=0)\n","test_mse_3,test_accuracy_3 = best_model.evaluate(x_3_ts, y_3_ts,verbose=0)\n","print('Training MSE: %.6f Test MSE: %.6f'%(training_mse_3,test_mse_3))\n","print('Training accuracy: %.4f Test accuracy: %.4f'%(training_accuracy_3,test_accuracy_3))\n","\n"],"metadata":{"id":"JlKWmpi9VqDb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Risultati"],"metadata":{"id":"lYN3dOX34D7V"}},{"cell_type":"code","source":["\n","print('Training MSE: %.4f Test MSE: %.4f'%(training_mse_3,test_mse_3))\n","print('Training accuracy: %.4f Test accuracy: %.4f'%(training_accuracy_3,test_accuracy_3))\n","pyplot.title('MONK 3')\n","pyplot.plot(history_best_3.history['loss'], label='training')\n","pyplot.plot(history_best_3.history['val_loss'], label='test', linestyle=\"dashed\")\n","pyplot.xlabel('epoch')\n","pyplot.ylabel('MSE')\n","pyplot.legend()\n","pyplot.show()"],"metadata":{"id":"imWpHzWpZjmu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","print('Training MSE: %.4f Test MSE: %.4f'%(training_mse_3,test_mse_3))\n","print('Training accuracy: %.4f Test accuracy: %.4f'%(training_accuracy_3,test_accuracy_3))\n","pyplot.title('MONK 3 ACCURACY')\n","pyplot.plot(history_best_3.history['accuracy'], label='training')\n","pyplot.plot(history_best_3.history['val_accuracy'], label='test', linestyle=\"dashed\")\n","pyplot.xlabel('epoch')\n","pyplot.ylabel('MSE')\n","pyplot.legend()\n","pyplot.show()"],"metadata":{"id":"_pnOTyu9xR32"},"execution_count":null,"outputs":[]}]}